# -*- coding: utf-8 -*-
"""Copy of Churn Prediction for ConnectSphere Telecom.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d9c30oIUjoDAgOS_osBMt1Emtk2Tjd7r
"""

# ðŸ“˜ Churn Prediction for ConnectSphere Telecom
print('Hello from YBI Foundation ðŸš€')

# Step 1: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

!find /content/drive/MyDrive -type f -name "*.csv"

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Path in Google Drive where the file will be saved
save_path = '/content/drive/MyDrive/ybidatasetmount_files/Telco-Customer-Churn.csv'

# Download the dataset from GitHub directly to your Drive folder
!wget -O "$save_path" https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv

# Load the CSV into a DataFrame
import pandas as pd
df = pd.read_csv(save_path)
df.head()

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/ybidatasetmount_files/Telco-Customer-Churn.csv')
df.head()

# Basic dataset info
df.info()
df.describe()
df.isnull().sum()

# Drop customerID (not useful for prediction)
df = df.drop(columns=['customerID'])

# Convert TotalCharges to numeric (some may be empty strings)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Fill missing TotalCharges with median
df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)

# Encode categorical columns
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for col in df.select_dtypes(include=['object']).columns:
    df[col] = le.fit_transform(df[col])

# Features and target
X = df.drop(columns=['Churn'])
y = df['Churn']

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Preprocessing complete âœ…")

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define ANN model
model = keras.Sequential([
    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train,
                    validation_split=0.2,
                    epochs=50,
                    batch_size=32,
                    verbose=1)

# Evaluate on test set
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.4f}")

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import numpy as np

# Predict probabilities
y_pred_probs = model.predict(X_test)

# Convert probabilities to binary labels
y_pred = (y_pred_probs > 0.5).astype(int)

# Classification report
print("Classification Report:\n")
print(classification_report(y_test, y_pred))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Not Churn', 'Churn'],
            yticklabels=['Not Churn', 'Churn'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Save the model
model.save("/content/drive/MyDrive/churn_prediction_model.h5")
print("Model saved successfully!")

# Load the model later
from tensorflow.keras.models import load_model
loaded_model = load_model("/content/drive/MyDrive/churn_prediction_model.h5")
print("Model loaded successfully!")

# Predict on the test set
y_pred_prob = loaded_model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)

# Evaluate accuracy and F1-score
from sklearn.metrics import accuracy_score, f1_score, classification_report

print("Accuracy:", accuracy_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))